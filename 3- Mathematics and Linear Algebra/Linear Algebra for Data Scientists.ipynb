{"cells":[{"metadata":{"_uuid":"726661972b09b03a31d424ef02a9be0cd284d81b"},"cell_type":"markdown","source":" # <div style=\"text-align: center\">Linear Algebra for Data Scientists \n<div style=\"text-align: center\">\nHaving a basic knowledge of linear algebra is one of the requirements for any data scientist. In this tutorial we will try to cover all the necessary concepts related to linear algebra\nand also this is the third step of the <a href=\"https://www.kaggle.com/mjbahmani/10-steps-to-become-a-data-scientist\">10 Steps to Become a Data Scientist</a>. and you can learn all of the thing you need for being a data scientist with Linear Algabra.</div> \n\n<div style=\"text-align:center\">last update: <b>03/01/2019</b></div>\n\n>###### You may  be interested have a look at 10 Steps to Become a Data Scientist: \n\n1. [Leren Python](https://www.kaggle.com/mjbahmani/the-data-scientist-s-toolbox-tutorial-1)\n2. [Python Packages](https://www.kaggle.com/mjbahmani/the-data-scientist-s-toolbox-tutorial-2)\n3. <font color=\"red\">You are in 3th step</font>\n4. [Programming &amp; Analysis Tools](https://www.kaggle.com/mjbahmani/20-ml-algorithms-15-plot-for-beginners)\n5. [Big Data](https://www.kaggle.com/mjbahmani/a-data-science-framework-for-quora)\n6. [Data visualization](https://www.kaggle.com/mjbahmani/top-5-data-visualization-libraries-tutorial)\n7. [Data Cleaning](https://www.kaggle.com/mjbahmani/machine-learning-workflow-for-house-prices)\n8. [How to solve a Problem?](https://www.kaggle.com/mjbahmani/the-data-scientist-s-toolbox-tutorial-2)\n9. [Machine Learning](https://www.kaggle.com/mjbahmani/a-comprehensive-ml-workflow-with-python)\n10. [Deep Learning](https://www.kaggle.com/mjbahmani/top-5-deep-learning-frameworks-tutorial)\n\n\n\n\n\nYou can Fork code  and  Follow me on:\n\n> ###### [ GitHub](https://github.com/mjbahmani/10-steps-to-become-a-data-scientist)\n> ###### [Kaggle](https://www.kaggle.com/mjbahmani/)\n-------------------------------------------------------------------------------------------------------------\n <b>I hope you find this kernel helpful and some <font color='blue'>UPVOTES</font> would be very much appreciated.</b>\n    \n -----------"},{"metadata":{"_uuid":"2a01be35950f7a117fc6700e866de3bf5a3ea6b9"},"cell_type":"markdown","source":" <a id=\"top\"></a> <br>\n## Notebook  Content\n1. [Introduction](#1)\n1. [What is Linear Algebra?](#2)\n1. [Notation ](#2)\n1. [Matrix Multiplication](#3)\n    1. [Vector-Vector Products](#31)\n    1. [Outer Product of Two Vectors](#32)\n    1. [Matrix-Vector Products](#33)\n    1. [Matrix-Matrix Products](#34)\n1. [Identity Matrix](#4)\n1. [Diagonal Matrix](#5)\n1. [Transpose of a Matrix](#6)\n1. [Symmetric Metrices](#7)\n1. [The Trace](#8)\n1. [Norms](#9)\n1. [Linear Independence and Rank](#10)\n1. [Subtraction and Addition of Metrices](#11)\n    1. [Inverse](#111)\n1. [Orthogonal Matrices](#12)\n1. [Range and Nullspace of a Matrix](#13)\n1. [Determinant](#14)\n1. [Tensors](#16)\n1. [Hyperplane](#17)\n1. [Eigenvalues and Eigenvectors](#18)\n1. [Exercise](#19)\n1. [Conclusion](#21)\n1. [References](#22)"},{"metadata":{"_uuid":"b18443661b6d30ffea2150fa74d44d62e14ae952"},"cell_type":"markdown","source":"<a id=\"1\"></a> <br>\n#  1-Introduction\nThis is the third step of the [10 Steps to Become a Data Scientist](https://www.kaggle.com/mjbahmani/10-steps-to-become-a-data-scientist).\nwe will cover following topic:\n1. notation\n1. Matrix Multiplication\n1. Identity Matrix\n1. Diagonal Matrix\n1. Transpose of a Matrix\n1. The Trace\n1. Norms\n1. Tensors\n1. Hyperplane\n1. Eigenvalues and Eigenvectors\n## What is linear algebra?\n**Linear algebra** is the branch of mathematics that deals with **vector spaces**. good understanding of Linear Algebra is intrinsic to analyze Machine Learning algorithms, especially for **Deep Learning** where so much happens behind the curtain.you have my word that I will try to keep mathematical formulas & derivations out of this completely mathematical topic and I try to cover all of subject that you need as data scientist.[https://medium.com/@neuralnets](https://medium.com/@neuralnets/linear-algebra-for-data-science-revisiting-high-school-9a6bbeba19c6)\n<img src='https://camo.githubusercontent.com/e42ea0e40062cc1e339a6b90054bfbe62be64402/68747470733a2f2f63646e2e646973636f72646170702e636f6d2f6174746163686d656e74732f3339313937313830393536333530383733382f3434323635393336333534333331383532382f7363616c61722d766563746f722d6d61747269782d74656e736f722e706e67' height=200 width=700>\n[image credit: https://hadrienj.github.io/posts/Deep-Learning-Book-Series-2.1-Scalars-Vectors-Matrices-and-Tensors/ ](https://hadrienj.github.io/posts/Deep-Learning-Book-Series-2.1-Scalars-Vectors-Matrices-and-Tensors/)\n <a id=\"top\"></a> <br>"},{"metadata":{"_uuid":"9008e99d1ebea16694d75bfa1ba5addef515198e"},"cell_type":"markdown","source":"<a id=\"11\"></a> <br>\n## 1-1 Import"},{"metadata":{"trusted":true,"_uuid":"223d7c576e665b2bbb83894e4f24346738e95877","_kg_hide-input":true},"cell_type":"code","source":"import matplotlib.patches as patch\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\nfrom scipy import linalg\nfrom numpy import poly1d\nfrom sklearn import svm\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport glob\nimport sys\nimport os","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"286ce03c993f8784863f6ad59298c869f8a544b0"},"cell_type":"markdown","source":"<a id=\"12\"></a> <br>\n##  1-2 Setup"},{"metadata":{"trusted":true,"_uuid":"480928dbf26d5ef6ac7a1ddfe59b51a5eb95338a","_kg_hide-input":true},"cell_type":"code","source":"%matplotlib inline\n%precision 4\nplt.style.use('ggplot')\nnp.set_printoptions(suppress=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e6824a84cbdfb6dc17200c495101e113967bf514"},"cell_type":"markdown","source":"<a id=\"2\"></a> <br>\n# 2- What is Linear Algebra?\nLinear algebra is the branch of mathematics concerning linear equations such as\n<img src='https://wikimedia.org/api/rest_v1/media/math/render/svg/f4f0f2986d54c01f3bccf464d266dfac923c80f3'>\nLinear algebra is central to almost all areas of mathematics. [6]\n<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/2/2f/Linear_subspaces_with_shading.svg/800px-Linear_subspaces_with_shading.svg.png' height=400 width=400>\n[wikipedia](https://en.wikipedia.org/wiki/Linear_algebra#/media/File:Linear_subspaces_with_shading.svg)\n"},{"metadata":{"trusted":true,"_uuid":"9d1e3eceee8943fb0b6086abfc68ae6634a6cac3","_kg_hide-input":true},"cell_type":"code","source":"# let see how to create a multi dimentional Array with Numpy\na = np.zeros((2, 3, 4))\n#l = [[[ 0.,  0.,  0.,  0.],\n    #      [ 0.,  0.,  0.,  0.],\n     #     [ 0.,  0.,  0.,  0.]],\n     #     [[ 0.,  0.,  0.,  0.],\n    #      [ 0.,  0.,  0.,  0.],\n     #     [ 0.,  0.,  0.,  0.]]]\nprint(a)\nprint(a.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f3396b3c3597ea3a45209181fe86730750ea0b7","_kg_hide-input":true},"cell_type":"code","source":"\n# Declaring Vectors\n\nx = [1, 2, 3]\ny = [4, 5, 6]\n\nprint(type(x))\n\n# This does'nt give the vector addition.\nprint(x + y)\n\n# Vector addition using Numpy\n\nz = np.add(x, y)\nprint(z)\nprint(type(z))\n\n# Vector Cross Product\nmul = np.cross(x, y)\nprint(mul)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"49c0b3e90c95512ef3733b25fd87cdef8ce31f97"},"cell_type":"markdown","source":"## 2-1 What is Vectorization?\nIn mathematics, especially in linear algebra and matrix theory, the vectorization of a matrix is a linear transformation which converts the matrix into a column vector. Specifically, the vectorization of an m × n matrix A, denoted vec(A), is the mn × 1 column vector obtained by stacking the columns of the matrix A on top of one another:\n<img src='https://wikimedia.org/api/rest_v1/media/math/render/svg/30ca6a8b796fd3a260ba3001d9875e990baad5ab'>\n[wikipedia](https://en.wikipedia.org/wiki/Vectorization_(mathematics) )"},{"metadata":{"_uuid":"dbea06c756c0c9e398def8799d080e23b3e5f899"},"cell_type":"markdown","source":"Vectors of the length $n$ could be treated like points in $n$-dimensional space. One can calculate the distance between such points using measures like [Euclidean Distance](https://en.wikipedia.org/wiki/Euclidean_distance). The similarity of vectors could also be calculated using [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity).\n###### [Go to top](#top)"},{"metadata":{"_uuid":"edaec8965119aa83192198d2d440c37546335719"},"cell_type":"markdown","source":"<a id=\"3\"></a> <br>\n## 3- Notation\n<img src='http://s8.picofile.com/file/8349058626/la.png'>\n[linear.ups.edu](http://linear.ups.edu/html/notation.html)"},{"metadata":{"_uuid":"41bc780d93b81da8aa1ff806c54a4791dbb2c8dc"},"cell_type":"markdown","source":"<a id=\"4\"></a> <br>\n## 4- Matrix Multiplication\n<img src='https://www.mathsisfun.com/algebra/images/matrix-multiply-constant.gif'>\n\n[mathsisfun](https://www.mathsisfun.com/algebra/matrix-multiplying.html)"},{"metadata":{"_uuid":"0573f52724da68f860328d1cc3259c215d817f80"},"cell_type":"markdown","source":"The result of the multiplication of two matrixes $A \\in \\mathbb{R}^{m \\times n}$ and $B \\in \\mathbb{R}^{n \\times p}$ is the matrix:"},{"metadata":{"trusted":true,"_uuid":"788f078e069a2ace3ca7d0aead749ead8b248c6d","_kg_hide-input":true},"cell_type":"code","source":"# initializing matrices \nx = np.array([[1, 2], [4, 5]]) \ny = np.array([[7, 8], [9, 10]])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bd6307c19afbda119a0dacca7e096b965889a30b"},"cell_type":"markdown","source":"$C = AB \\in \\mathbb{R}^{m \\times n}$"},{"metadata":{"_uuid":"0e0a76e86724698f241fcc74fc37e54d881622bd"},"cell_type":"markdown","source":"That is, we are multiplying the columns of $A$ with the rows of $B$:"},{"metadata":{"_uuid":"adb65bab1beb10117cbb490383cb62a9578ce62f"},"cell_type":"markdown","source":"$C_{ij}=\\sum_{k=1}^n{A_{ij}B_{kj}}$\n<img src='https://cdn.britannica.com/06/77706-004-31EE92F3.jpg'>\n[reference](https://cdn.britannica.com/06/77706-004-31EE92F3.jpg)"},{"metadata":{"_uuid":"17f45fb4f428ad87706493da0431bdce6c00b531"},"cell_type":"markdown","source":"The number of columns in $A$ must be equal to the number of rows in $B$.\n\n###### [Go to top](#top)"},{"metadata":{"trusted":true,"_uuid":"3cf4286adffc483893952a31d5a7006c462b3f60","_kg_hide-input":true},"cell_type":"code","source":"# using add() to add matrices \nprint (\"The element wise addition of matrix is : \") \nprint (np.add(x,y)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"911a916a2c725232349a832769dd794956cb88cb","_kg_hide-input":true},"cell_type":"code","source":"# using subtract() to subtract matrices \nprint (\"The element wise subtraction of matrix is : \") \nprint (np.subtract(x,y)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"045eba6b777e062510cfa4bf055c680830a66036","_kg_hide-input":true},"cell_type":"code","source":"# using divide() to divide matrices \nprint (\"The element wise division of matrix is : \") \nprint (np.divide(x,y)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa8078d3057e8169d29ea9730d483ce9aebd5f2f","_kg_hide-input":true},"cell_type":"code","source":"# using multiply() to multiply matrices element wise \nprint (\"The element wise multiplication of matrix is : \") \nprint (np.multiply(x,y))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aa352f5ba3a8ee911eb8f1c03749267eb4c4f76e"},"cell_type":"markdown","source":"<a id=\"41\"></a> <br>\n## 4-1 Vector-Vector Products\n\nnumpy.cross(a, b, axisa=-1, axisb=-1, axisc=-1, axis=None)[source]\nReturn the cross product of two (arrays of) vectors.[scipy](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.cross.html)\n<img src='http://gamedevelopertips.com/wp-content/uploads/2017/11/image8.png'>\n[image-gredits](http://gamedevelopertips.com)"},{"metadata":{"_uuid":"371da89fa6d1b698c59ee82d6aa7b475fd7a5625","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x = [1, 2, 3]\ny = [4, 5, 6]\nnp.cross(x, y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4d8ffa140774c6a7e2f0cd35c4809bd80069ce8b"},"cell_type":"markdown","source":"We define the vectors $x$ and $y$ using *numpy*:"},{"metadata":{"_uuid":"e6c39782297031e83d0e695fa80f9ebc2a817f4f","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x = np.array([1, 2, 3, 4])\ny = np.array([5, 6, 7, 8])\nprint(\"x:\", x)\nprint(\"y:\", y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba7b567d2a4696cf0739e12cf4415ea3b8110e1e"},"cell_type":"markdown","source":"We can now calculate the $dot$ or $inner product$ using the *dot* function of *numpy*:"},{"metadata":{"_uuid":"c9fd9b61bdfa83059272f1ad61067138d0763308","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"np.dot(x, y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fec79e95e9d5b4059f91fd69334569a6831b835b"},"cell_type":"markdown","source":"The order of the arguments is irrelevant:"},{"metadata":{"_uuid":"d3843ed486083fd994883be64136127728d09d7e","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"np.dot(y, x)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4025fa080136e50fcc4749100946148fa508ce32"},"cell_type":"markdown","source":"Note that both vectors are actually **row vectors** in the above code. We can transpose them to column vectors by using the *shape* property:"},{"metadata":{"_uuid":"f3a97f695aad46b1d848469240308024d1dcb634","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print(\"x:\", x)\nx.shape = (4, 1)\nprint(\"xT:\", x)\nprint(\"y:\", y)\ny.shape = (4, 1)\nprint(\"yT:\", y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a850ef7d0e2025dd57cbf89c4bbe4146ed83ba4"},"cell_type":"markdown","source":"In fact, in our understanding of Linear Algebra, we take the arrays above to represent **row vectors**. *Numpy* treates them differently."},{"metadata":{"_uuid":"b64cdd134c53e7865a76d4efecc2ace176c664cd"},"cell_type":"markdown","source":"We see the issues when we try to transform the array objects. Usually, we can transform a row vector into a column vector in *numpy* by using the *T* method on vector or matrix objects:\n###### [Go to top](#top)"},{"metadata":{"_uuid":"bb73c80a401c89d79dbd920e5d63cf1a07b384e7","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x = np.array([1, 2, 3, 4])\ny = np.array([5, 6, 7, 8])\nprint(\"x:\", x)\nprint(\"y:\", y)\nprint(\"xT:\", x.T)\nprint(\"yT:\", y.T)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e80fc9e4bec6d2cc26a8194e19736e1f24484d5f"},"cell_type":"markdown","source":"The problem here is that this does not do, what we expect it to do. It only works, if we declare the variables not to be arrays of numbers, but in fact a matrix:"},{"metadata":{"_uuid":"cb78424e23837608cbd597fb6fc7c3cbd99f368a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x = np.array([[1, 2, 3, 4]])\ny = np.array([[5, 6, 7, 8]])\nprint(\"x:\", x)\nprint(\"y:\", y)\nprint(\"xT:\", x.T)\nprint(\"yT:\", y.T)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9bed60bdfd536f42ad4a88a358e611fef07bc14a"},"cell_type":"markdown","source":"Note that the *numpy* functions *dot* and *outer* are not affected by this distinction. We can compute the dot product using the mathematical equation above in *numpy* using the new $x$ and $y$ row vectors:\n###### [Go to top](#top)"},{"metadata":{"_uuid":"df9c92e49f2dad24800996d0655caccec351c580","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print(\"x:\", x)\nprint(\"y:\", y.T)\nnp.dot(x, y.T)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c1705fc2b1b16b9228274a2f53cd0fa59a39d8fd"},"cell_type":"markdown","source":"Or by reverting to:"},{"metadata":{"_uuid":"3a86b041668670f66b643053dfecfc46bdcd2749","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print(\"x:\", x.T)\nprint(\"y:\", y)\nnp.dot(y, x.T)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"13ebfb31e281db7417cc3e2beb312e63f9688e28"},"cell_type":"markdown","source":"To read the result from this array of arrays, we would need to access the value this way:"},{"metadata":{"_uuid":"295be78d3c1258ec4f24579985c5f14f8746e8a9","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"np.dot(y, x.T)[0][0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b5bda4ac75a8d11935ef765b2c869e56d9df8a56"},"cell_type":"markdown","source":"<a id=\"42\"></a> <br>\n## 4-2 Outer Product of Two Vectors\nCompute the outer product of two vectors."},{"metadata":{"_uuid":"31c5791cb210071f5253d0a20a7f1e2c030a48ea","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x = np.array([[1, 2, 3, 4]])\nprint(\"x:\", x)\nprint(\"xT:\", np.reshape(x, (4, 1)))\nprint(\"xT:\", x.T)\nprint(\"xT:\", x.transpose())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79454aca18aaa191658d04a48662f75588dd6e4e"},"cell_type":"markdown","source":"Example\n###### [Go to top](#top)"},{"metadata":{"_uuid":"0f8844018b2de3e4cd9584350a223b1e1347efe9"},"cell_type":"markdown","source":"We can now compute the **outer product** by multiplying the column vector $x$ with the row vector $y$:"},{"metadata":{"_uuid":"4744a491b80ce1e01ddc4590847c9660ea9ae14b","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x = np.array([[1, 2, 3, 4]])\ny = np.array([[5, 6, 7, 8]])\nx.T * y","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ee36e496adf686e1445faca7e5c9c1dee9abf35"},"cell_type":"markdown","source":"*Numpy* provides an *outer* function that does all that:"},{"metadata":{"_uuid":"47ce570eb9aa9a1173a2f30de728aba2aec3976c","trusted":true},"cell_type":"code","source":"np.outer(x, y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b3eed151fe4f34604d1691e36a41d82b36d3fead"},"cell_type":"markdown","source":"Note, in this simple case using the simple arrays for the data structures of the vectors does not affect the result of the *outer* function:"},{"metadata":{"_uuid":"e52b29787ddf67293d7dbe6f0887cfc23fc4f11f","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x = np.array([1, 2, 3, 4])\ny = np.array([5, 6, 7, 8])\nnp.outer(x, y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0497e5d541a3c1ba344863a6730ea7521e65d50c"},"cell_type":"markdown","source":"<a id=\"43\"></a> <br>\n## 4-3 Matrix-Vector Products\nUse numpy.dot or a.dot(b). See the documentation [here](http://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html)."},{"metadata":{"_uuid":"dab712cc9bfed1169b78e17b899fb51ab054323a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"a = np.array([[ 5, 1 ,3], [ 1, 1 ,1], [ 1, 2 ,1]])\nb = np.array([1, 2, 3])\nprint (a.dot(b))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2be29c242244536effade27bc0f8bbd03eddd537"},"cell_type":"markdown","source":"Using *numpy* we can compute $Ax$:"},{"metadata":{"_uuid":"00f0a534b7dae7a24ee27a74553e1f785f3714ef","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"A = np.array([[4, 5, 6],\n             [7, 8, 9]])\nx = np.array([1, 2, 3])\nA.dot(x)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"baee0e90e0271a893fa7344c7fbecb17849e24cb"},"cell_type":"markdown","source":"<a id=\"44\"></a> <br>\n## 4-4 Matrix-Matrix Products"},{"metadata":{"trusted":true,"_uuid":"e195d447d2cef723907f73cd692b9dc3ce17e271"},"cell_type":"code","source":"a = [[1, 0], [0, 1]]\nb = [[4, 1], [2, 2]]\nnp.matmul(a, b)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da4f41de85c7b81e7b12eb2aa5d96f36b9239795","_kg_hide-input":true},"cell_type":"code","source":"matrix1 = np.matrix(a)\nmatrix2 = np.matrix(b)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8fff3d143c70a997cb601ce8440f3e98ba4be645","_kg_hide-input":true},"cell_type":"code","source":"matrix1 + matrix2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80a8ae1787a4ca1aedc4ec0bfc9ec7ca36935209"},"cell_type":"code","source":"matrix1 - matrix2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ee80826d7e34cb283c5ff4ef165d05f7715fe14f"},"cell_type":"markdown","source":"<a id=\"441\"></a> <br>\n### 4-4-1  Multiplication"},{"metadata":{"trusted":true,"_uuid":"413b954a7fce564c58d2bab2c0e48c8a268ca706"},"cell_type":"code","source":"np.dot(matrix1, matrix2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71a943f0cf2b0a27001ed6e53a766f2626946587"},"cell_type":"code","source":"\nmatrix1 * matrix2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42bf81d28ea53bf258944612b436bf9a3a6b1292"},"cell_type":"markdown","source":"<a id=\"5\"></a> <br>\n## 5- Identity Matrix"},{"metadata":{"_uuid":"2cb80bc7e181a316499f1c420d6504714a887c98"},"cell_type":"markdown","source":"numpy.identity(n, dtype=None)\n\nReturn the identity array.\n[source](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.identity.html)"},{"metadata":{"trusted":true,"_uuid":"842b12bf0ffff4ab4252db3134ca16eb44d2bc89"},"cell_type":"code","source":"np.identity(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"be61bed3414ed2dccb551abbffb0a58ba270d38d"},"cell_type":"markdown","source":"How to create *identity matrix* in *numpy*  "},{"metadata":{"_uuid":"29068a6e863dff19854170ea9ef701385d4ebda7","trusted":true},"cell_type":"code","source":"identy = np.array([[21, 5, 7],[9, 8, 16]])\nprint(\"identy:\", identy)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"41d1470cef878a6ea9d6db819ca44bf5ebc7232e","trusted":true},"cell_type":"code","source":"identy.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70d0df8d58e0a9209bcaa5753c51d3e8d905ce40","trusted":true},"cell_type":"code","source":"np.identity(identy.shape[1], dtype=\"int\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ac179dd27c16233d91df6ef504de64e5fadb7c8","trusted":true},"cell_type":"code","source":"np.identity(identy.shape[0], dtype=\"int\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7f97a3211e646d8ffc467bcda3623da3b89b9202"},"cell_type":"markdown","source":"<a id=\"51\"></a> <br>\n### 5-1  Inverse Matrices"},{"metadata":{"trusted":true,"_uuid":"2e0fdf7abf02064addfb5acf23b751dbf8e8fc1f"},"cell_type":"code","source":"inverse = np.linalg.inv(matrix1)\nprint(inverse)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"93c10865c2374f850dd040b8d545c226002dbb75"},"cell_type":"markdown","source":"<a id=\"6\"></a> <br>\n## 6- Diagonal Matrix"},{"metadata":{"_uuid":"10c74f8237e9f95bcc0e47cf5b2c0beba8b39b01"},"cell_type":"markdown","source":"In *numpy* we can create a *diagonal matrix* from any given matrix using the *diag* function:"},{"metadata":{"_uuid":"51b5323cf73f7e328f3c8c024fd634e33329235b","trusted":true},"cell_type":"code","source":"import numpy as np\nA = np.array([[0,   1,  2,  3],\n              [4,   5,  6,  7],\n              [8,   9, 10, 11],\n              [12, 13, 14, 15]])\nnp.diag(A)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"213118a89acd75f4ca025d46b319037cd1bcbbf8","trusted":true},"cell_type":"code","source":"np.diag(A, k=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70526663a463f5cdb1214fcf5ea2f7f3fb9ce166","trusted":true},"cell_type":"code","source":"np.diag(A, k=-1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"87d1e66c2fdd87db8a4b6e7b2dfee28d66dfd3fa"},"cell_type":"markdown","source":"<a id=\"7\"></a> <br>\n## 7- Transpose of a Matrix\nFor reading about Transpose of a Matrix, you can visit [this link](https://py.checkio.org/en/mission/matrix-transpose/)"},{"metadata":{"trusted":true,"_uuid":"dea9e2ef7ac37cb7b1ce919c68bb0b352e01fff7"},"cell_type":"code","source":"a = np.array([[1, 2], [3, 4]])\na","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e8a6944750b79de14323af2d68b6cfac7bcf192"},"cell_type":"code","source":"a.transpose()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2862a79e4c2abaede94a473a74f5eee9c07be65d"},"cell_type":"markdown","source":"<a id=\"8\"></a> <br>\n## 8- Symmetric Matrices\nIn linear algebra, a symmetric matrix is a square matrix that is equal to its transpose. Formally,\n<img src='https://wikimedia.org/api/rest_v1/media/math/render/svg/ad8a5a3a4c95de6f7f50b0a6fb592d115fe0e95f'>\n\n[wikipedia](https://en.wikipedia.org/wiki/Symmetric_matrix)"},{"metadata":{"trusted":true,"_uuid":"d859ccb55b0e40c4261314d69731be42efa5c03f"},"cell_type":"code","source":"N = 100\nb = np.random.random_integers(-2000,2000,size=(N,N))\nb_symm = (b + b.T)/2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"428183208acf9df58cd241a7cd0ede7e17baf3d1"},"cell_type":"markdown","source":"<a id=\"9\"></a> <br>\n## 9-The Trace\nReturn the sum along diagonals of the array."},{"metadata":{"_uuid":"17f061ccf8620270700b566eea8e41b70f215960","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"np.trace(np.eye(3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03ec16794b2e1b2c5204eb5da7e03769fac509bf"},"cell_type":"code","source":"print(np.trace(matrix1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4c042172e851dc79b63674dba2751f3b742fff7"},"cell_type":"code","source":"det = np.linalg.det(matrix1)\nprint(det)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0b5536a2d51d252ff8ed7c972f407c1669fac6ab"},"cell_type":"markdown","source":"<a id=\"10\"></a> <br>\n# 10- Norms\nnumpy.linalg.norm\nThis function is able to return one of eight different matrix norms, or one of an infinite number of vector norms (described below), depending on the value of the ord parameter. [scipy](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.linalg.norm.html)\n\n <a id=\"top\"></a> <br>"},{"metadata":{"trusted":true,"_uuid":"d8232fcb5a3b7ef9f9dab45d8d964046c584da11"},"cell_type":"code","source":"v = np.array([1,2,3,4])\nnorm.median(v)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42d54d284146a24f5eeedffa8c53ed870359b08d"},"cell_type":"markdown","source":"<a id=\"11\"></a> <br>\n# 11- Linear Independence and Rank\nHow to identify the linearly independent rows from a matrix?"},{"metadata":{"trusted":true,"_uuid":"99bc735946faf655e15a2065eb81b0e1db9c8565"},"cell_type":"code","source":"#How to find linearly independent rows from a matrix\nmatrix = np.array(\n    [\n        [0, 1 ,0 ,0],\n        [0, 0, 1, 0],\n        [0, 1, 1, 0],\n        [1, 0, 0, 1]\n    ])\n\nlambdas, V =  np.linalg.eig(matrix.T)\n# The linearly dependent row vectors \nprint (matrix[lambdas == 0,:])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e3cf40ea16ea61ebd53a5b56d1ecccf3ebfeba50"},"cell_type":"markdown","source":"<a id=\"12\"></a> <br>\n# 12-  Subtraction and Addition of Metrices"},{"metadata":{"_uuid":"fa3526c6b6308ae79ab322ff12e6e21e45761e8a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nprint(\"np.arange(9):\", np.arange(9))\nprint(\"np.arange(9, 18):\", np.arange(9, 18))\nA = np.arange(9, 18).reshape((3, 3))\nB = np.arange(9).reshape((3, 3))\nprint(\"A:\", A)\nprint(\"B:\", B)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2c2f223e42500cdc89887cf0c9c3a5bb2fd2497c"},"cell_type":"markdown","source":"We can now add and subtract the two matrices $A$ and $B$:"},{"metadata":{"_uuid":"3882778eea130a7cc3fd3e32d66177e6d5715223","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"A + B","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"00e586d7bdee0508f12ec92f4742994813ce0f79","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"A - B","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"94127d106aa8e05925e99e5f6c0a70f2c860af39"},"cell_type":"markdown","source":"<a id=\"121\"></a> <br>\n## 12-1 Inverse\nWe use numpy.linalg.inv() function to calculate the inverse of a matrix. The inverse of a matrix is such that if it is multiplied by the original matrix, it results in identity matrix.[tutorialspoint](https://www.tutorialspoint.com/numpy/numpy_inv.htm)"},{"metadata":{"trusted":true,"_uuid":"4bf2c911607f01aa47a4188d8212a9c6abae1972"},"cell_type":"code","source":"x = np.array([[1,2],[3,4]]) \ny = np.linalg.inv(x) \nprint (x )\nprint (y )\nprint (np.dot(x,y))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6d67e21b6e3c3131310b7208bac880550e61ad03"},"cell_type":"markdown","source":"<a id=\"13\"></a> <br>\n## 13- Orthogonal Matrices\nHow to create random orthonormal matrix in python numpy"},{"metadata":{"trusted":true,"_uuid":"fca71217a54595fb76f02e9044b3090ea75ffb80","_kg_hide-input":true},"cell_type":"code","source":"## based on https://stackoverflow.com/questions/38426349/how-to-create-random-orthonormal-matrix-in-python-numpy\ndef rvs(dim=3):\n     random_state = np.random\n     H = np.eye(dim)\n     D = np.ones((dim,))\n     for n in range(1, dim):\n         x = random_state.normal(size=(dim-n+1,))\n         D[n-1] = np.sign(x[0])\n         x[0] -= D[n-1]*np.sqrt((x*x).sum())\n         # Householder transformation\n         Hx = (np.eye(dim-n+1) - 2.*np.outer(x, x)/(x*x).sum())\n         mat = np.eye(dim)\n         mat[n-1:, n-1:] = Hx\n         H = np.dot(H, mat)\n         # Fix the last sign such that the determinant is 1\n     D[-1] = (-1)**(1-(dim % 2))*D.prod()\n     # Equivalent to np.dot(np.diag(D), H) but faster, apparently\n     H = (D*H.T).T\n     return H","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"84a7cc36920151c3166ad9036173a975077a816e"},"cell_type":"markdown","source":"<a id=\"14\"></a> <br>\n## 14- Range and Nullspace of a Matrix"},{"metadata":{"trusted":true,"_uuid":"dfc7ff00eea809bf00d3dacc6b3a5db13562c7a6"},"cell_type":"code","source":"from scipy.linalg import null_space\nA = np.array([[1, 1], [1, 1]])\nns = null_space(A)\nns * np.sign(ns[0,0])  # Remove the sign ambiguity of the vector","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5168e46a20736d3815f9ac3590ab129b732bee12"},"cell_type":"markdown","source":"<a id=\"15\"></a> <br>\n# 15-  Determinant\nCompute the determinant of an array"},{"metadata":{"trusted":true,"_uuid":"94b4e5d5a484fa851174e8a610c9c91dad83c37a"},"cell_type":"code","source":"a = np.array([[1, 2], [3, 4]])\nnp.linalg.det(a)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c03b0d7f8c0409ac026d6c7274cfaf95b572a26c"},"cell_type":"markdown","source":"<a id=\"16\"></a> <br>\n# 16- Tensors"},{"metadata":{"_uuid":"baf22e2a7f0a839a26df2a17815b6f2867dc7c15"},"cell_type":"markdown","source":"A [**tensor**](https://en.wikipedia.org/wiki/Tensor) could be thought of as an organized multidimensional array of numerical values. A vector could be assumed to be a sub-class of a tensor. Rows of tensors extend alone the y-axis, columns along the x-axis. The **rank** of a scalar is 0, the rank of a **vector** is 1, the rank of a **matrix** is 2, the rank of a **tensor** is 3 or higher.\n\n###### [Go to top](#top)"},{"metadata":{"trusted":true,"_uuid":"3bb2dbff06ab25e05e379d45b5f529c94d2bf6aa","_kg_hide-input":true},"cell_type":"code","source":"# credits: https://www.tensorflow.org/api_docs/python/tf/Variable\nA = tf.Variable(np.zeros((5, 5), dtype=np.float32), trainable=False)\nnew_part = tf.ones((2,3))\nupdate_A = A[2:4,2:5].assign(new_part)\nsess = tf.InteractiveSession()\ntf.global_variables_initializer().run()\nprint(update_A.eval())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9585bfae0dd3cd9de762cf8d5ffb801a2b24dc08"},"cell_type":"markdown","source":"<a id=\"25\"></a> <br>\n# 17- Hyperplane"},{"metadata":{"_uuid":"e689830f047dd755c68f83b0a4747928eb70c044"},"cell_type":"markdown","source":"The **hyperplane** is a sub-space in the ambient space with one dimension less. In a two-dimensional space the hyperplane is a line, in a three-dimensional space it is a two-dimensional plane, etc."},{"metadata":{"_uuid":"2f4ff05c6a2421c9e41d326d29970ff6be1b3695"},"cell_type":"markdown","source":"Hyperplanes divide an $n$-dimensional space into sub-spaces that might represent clases in a machine learning algorithm."},{"metadata":{"trusted":true,"_uuid":"43691809c6e28187520e3fce5fe89007dbda1166","_kg_hide-input":true},"cell_type":"code","source":"##based on this address: https://stackoverflow.com/questions/46511017/plot-hyperplane-linear-svm-python\nnp.random.seed(0)\nX = np.r_[np.random.randn(20, 2) - [2, 2], np.random.randn(20, 2) + [2, 2]]\nY = [0] * 20 + [1] * 20\n\nfig, ax = plt.subplots()\nclf2 = svm.LinearSVC(C=1).fit(X, Y)\n\n# get the separating hyperplane\nw = clf2.coef_[0]\na = -w[0] / w[1]\nxx = np.linspace(-5, 5)\nyy = a * xx - (clf2.intercept_[0]) / w[1]\n\n# create a mesh to plot in\nx_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\ny_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\nxx2, yy2 = np.meshgrid(np.arange(x_min, x_max, .2),\n                     np.arange(y_min, y_max, .2))\nZ = clf2.predict(np.c_[xx2.ravel(), yy2.ravel()])\n\nZ = Z.reshape(xx2.shape)\nax.contourf(xx2, yy2, Z, cmap=plt.cm.coolwarm, alpha=0.3)\nax.scatter(X[:, 0], X[:, 1], c=Y, cmap=plt.cm.coolwarm, s=25)\nax.plot(xx,yy)\n\nax.axis([x_min, x_max,y_min, y_max])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b488bdb25f40572d2493b54b3a60bfbaa4b0f5a"},"cell_type":"markdown","source":"<a id=\"31\"></a> <br>\n## 20- Exercises\nlet's do some exercise."},{"metadata":{"_uuid":"b3c3f294d5fe5ae84d6a9a5b9d3e136dea2f95f5"},"cell_type":"markdown","source":"### 20-1 Create a dense meshgrid"},{"metadata":{"trusted":true,"_uuid":"3a38d6cd29163b51c8769ab23831a31f0d964f3a"},"cell_type":"code","source":"np.mgrid[0:5,0:5]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9240bceba412008933a328882257b7ed80ae5eab"},"cell_type":"markdown","source":"### 20-2 Permute array dimensions"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"7487fcd5b4406f1d4f77538296631463e1b7f064"},"cell_type":"code","source":"a=np.array([1,2,3])\nb=np.array([(1+5j,2j,3j), (4j,5j,6j)])\nc=np.array([[(1.5,2,3), (4,5,6)], [(3,2,1), (4,5,6)]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"90a654b50a8d3b70948b491af19e60e78e42df2d"},"cell_type":"code","source":"np.transpose(b)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1cb51825fc92fe4ee6b967cfdb67f20c442f55fe"},"cell_type":"code","source":"b.flatten()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"17c2358795f13774f8f38186e661cf995e1ca4f1"},"cell_type":"code","source":"np.hsplit(c,2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8d2cf7c2ca2cd85c801444ab6dabe6e13c12a181"},"cell_type":"markdown","source":"## 20-3 Polynomials"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"90090cbf0e9c534675e574ad554f50b541aee42e"},"cell_type":"code","source":"p=poly1d([3,4,5])\np","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f8707181b8793a673db66d03a3a0c655a801b237"},"cell_type":"markdown","source":"## SciPy Cheat Sheet: Linear Algebra in Python\nThis Python cheat sheet is a handy reference with code samples for doing linear algebra with SciPy and interacting with NumPy.\n\n[DataCamp](https://www.datacamp.com/community/blog/python-scipy-cheat-sheet)"},{"metadata":{"_uuid":"afc2a360fedd783e5e9d7bbc975c9c6f06a2ee72"},"cell_type":"markdown","source":"<a id=\"21\"></a> <br>\n# 21-Conclusion\nIf you have made this far – give yourself a pat at the back. We have covered different aspects of **Linear algebra** in this Kernel. You are now finishing the **third step** of the course to continue, return to the [**main page**](https://www.kaggle.com/mjbahmani/10-steps-to-become-a-data-scientist/) of the course.  \n\n###### [Go to top](#top)"},{"metadata":{"_uuid":"b132163ee07917a0ab100b93f6ed5545ce0de45d"},"cell_type":"markdown","source":"you can follow me on:\n> ###### [ GitHub](https://github.com/mjbahmani/)\n> ###### [Kaggle](https://www.kaggle.com/mjbahmani/)\n\n <b>I hope you find this kernel helpful and some <font color='red'>UPVOTES</font> would be very much appreciated.<b/>\n "},{"metadata":{"_uuid":"5719a5ba111b65b20b53d538281ac773eb14471a"},"cell_type":"markdown","source":"<a id=\"22\"></a> <br>\n# 22-References & Credits\n1. [Linear Algbra1](https://github.com/dcavar/python-tutorial-for-ipython)\n1. [Linear Algbra2](https://www.oreilly.com/library/view/data-science-from/9781491901410/ch04.html)\n1. [datacamp](https://www.datacamp.com/community/blog/python-scipy-cheat-sheet)\n1. [damir.cavar](http://damir.cavar.me/)\n1. [Linear_algebra](https://en.wikipedia.org/wiki/Linear_algebra)\n1. [http://linear.ups.edu/html/fcla.html](http://linear.ups.edu/html/fcla.html)\n1. [mathsisfun](https://www.mathsisfun.com/algebra/matrix-multiplying.html)\n1. [scipy](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.outer.html)\n1. [tutorialspoint](https://www.tutorialspoint.com/numpy/numpy_inv.htm)\n1. [machinelearningmastery](https://machinelearningmastery.com/introduction-to-tensors-for-machine-learning/)\n1. [gamedevelopertips](http://gamedevelopertips.com/vector-in-game-development/)\n1. [Scalars-Vectors-Matrices-and-Tensors](https://hadrienj.github.io/posts/Deep-Learning-Book-Series-2.1-Scalars-Vectors-Matrices-and-Tensors/)"},{"metadata":{"_uuid":"f7d48149556ffed79e79cebf8aa53ca747b25b6e"},"cell_type":"markdown","source":"Go to first step: [Course Home Page](https://www.kaggle.com/mjbahmani/10-steps-to-become-a-data-scientist)\n\nGo to next step : [Titanic](https://www.kaggle.com/mjbahmani/a-comprehensive-ml-workflow-with-python)\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}